name: yolotester_dev

services:
  flower:
    image: mher/flower
    ports:
      - 5556:5555
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - FLOWER_PORT=5555
      - TZ=Asia/Tokyo
    depends_on:
      - redis

  celery:
    # image: ship:celery
    # image: jingandongbei/eii-new:dev-celery
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    command: celery -A apis.celery_worker worker --loglevel=info
    volumes:
      - ./backend:/backend
    environment:
      - UDEV=1
      - NVIDIA_VISIBLE_DEVICES=all  # 让容器可以访问所有 GPU
      - NVIDIA_DRIVER_CAPABILITIES=all  # 让容器具有完整的 GPU 功能（包括计算、视频等）
      - RESULT_DIR=/tmp/results
      - TZ=Asia/Tokyo
      - CELERY_TIMEZONE=Asia/Tokyo
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all  # 你可以指定具体的 GPU 数量，例如 '1' 只使用1个GPU
              capabilities: [gpu]
    runtime: nvidia
    env_file:
      - .dev_env

  backend:
    # image: lyl472324464/ship:backend-amd64
    build:
      context: ./backend
      dockerfile: Dockerfile
    restart: always
    ports:
      - "8008:8000"
    # command: python3 main.py
    command: sh -c "python3 main.py && uvicorn main:app --host 0.0.0.0 --port 8000 --reload"
    privileged: true
    working_dir: /backend
    volumes:
      - /dev:/dev
      - /run/udev:/run/udev:ro
      - ./backend:/backend
    devices:
      - /dev/bus/usb:/dev/bus/usb
    environment:
      - UDEV=1
      - TZ=Asia/Tokyo
    depends_on:
      # tritonserver:
      #   condition: service_started
      - mongo
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
    healthcheck:
      test: ["CMD-SHELL", "curl -f -X GET http://localhost:8000/api/health || exit 1"]
      interval: 30s     # 每 30 秒检查一次
      timeout: 10s      # 健康检查的超时时间为 10 秒
      retries: 3        # 连续失败 3 次，认为服务不健康
    ipc: host
    runtime: nvidia
    env_file:
      - .dev_env

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev
    volumes:
      - ./frontend:/frontend
    working_dir: /frontend
    restart: always
    environment:
      - TZ=Asia/Tokyo
    ports:
      - "3002:3000"
    depends_on:
      - backend

  minio:
    image: quay.io/minio/minio
    restart: always
    env_file:
      - .dev_env
    command: server --console-address ":9092" /data
    ports:
      - "9000:9000"
      - "9092:9092"
    volumes:
      - ./minio/data:/data

  # sudo chown -R 10001:10001 ./volumes/loki
  loki:
    image: grafana/loki:2.6.1
    ports:
      - "3100:3100"
    user: "10001:10001"
    volumes:
      # directory must be created first, with uid:gid 10001:10001
      - ./volumes/dev_loki:/loki
    environment:
      - TZ=Asia/Tokyo
    healthcheck:
      test: ["CMD", "wget","--spider", "http://localhost:3100/ready"]
      interval: 30s
      timeout: 10s
      retries: 3

  promtail:
    image: grafana/promtail:2.6.1
    volumes:
      # custom config will read logs from the containers of
      # this project
      - ./promtail/promtail-config.yaml:/etc/promtail/config.yml
      # to read container labels and logs
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/containers:/var/lib/docker/containers

  # will be available at http://127.0.0.1:3000
  # sudo chown -R 472:472 ./volumes/grafana
  grafana:
    image: grafana/grafana:9.2.2
    user: "472:472"
    ports:
      - "3001:3000"
    volumes:
      # directory must be created first, with uid:gid 472:472
      - ./volumes/grafana:/var/lib/grafana
      # automatically configure the loki datasource
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/grafana.ini:/etc/grafana/grafana.ini
    depends_on:
      loki:
        condition: service_healthy

  redis:
    image: redis:6.2.6
    restart: always
    ports:
      - "6379"

  mongo:
    image: mongo:7.0.6
    restart: no
    ports:
      - 27018:27017
    volumes:
      - ./mongo/data:/data/db
    healthcheck:
      test: ["CMD-SHELL", "mongosh --eval 'db.runCommand(\"ping\").ok' --quiet"]
      interval: 10s
      timeout: 5s
      retries: 3